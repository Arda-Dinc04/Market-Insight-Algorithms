{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ardadinc/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>-----------------------------Stock_Anaylsis.com Parsing Code-----------------------------<h3>\n",
    "<h6>url = 'https://stockanalysis.com/actions/splits/'<h6>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to /Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/StockAnalysis_Split_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the webpage that contains stock split data\n",
    "url = 'https://stockanalysis.com/actions/splits/'\n",
    "\n",
    "# Custom headers to mimic a browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Making the GET request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    # Find the table or div that contains the stock split data\n",
    "    table = soup.find('table')  # Assuming the data is in a table\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        data = []\n",
    "        for row in rows[1:]:  # Skipping the header row\n",
    "            cells = row.find_all('td')\n",
    "            if len(cells) > 1:\n",
    "                date_str = cells[0].text.strip()\n",
    "                date = datetime.strptime(date_str, \"%b %d, %Y\").strftime(\"%-m/%-d/%Y\")\n",
    "                symbol = cells[1].text.strip()\n",
    "                company_name = cells[2].text.strip()\n",
    "                split_type = cells[3].text.strip()\n",
    "                split_ratio = cells[4].text.strip().replace(\" for \", \" : \")\n",
    "                if \"forward\" not in split_type.lower():\n",
    "                    data.append([date, symbol, company_name, split_ratio])\n",
    "        \n",
    "        # Creating DataFrame without the Type column\n",
    "        df = pd.DataFrame(data, columns=['Date', 'Symbol', 'Company Name', 'Split Ratio'])\n",
    "        \n",
    "        # Saving DataFrame to CSV\n",
    "        output_file_path = '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/StockAnalysis_Split_Data.csv'\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "        print(f\"Data has been saved to {output_file_path}\")\n",
    "    else:\n",
    "        print(\"Failed to find the table containing stock split data.\")\n",
    "else:\n",
    "    print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>-----------------------------TipRanks.com Parsing Code-----------------------------<h3>\n",
    "<h6>url = 'https://www.tipranks.com/calendars/stock-splits/upcoming'<h6>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipranks data has been saved to /Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/Tipranks_Split_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Function to extract and process stock split data from tipranks.com\n",
    "def get_tipranks_data():\n",
    "    url = 'https://www.tipranks.com/calendars/stock-splits/upcoming'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    data = []\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        if table:\n",
    "            rows = table.find_all('tr')\n",
    "            for row in rows[1:]:  # Skip header row\n",
    "                cells = row.find_all('td')\n",
    "                if len(cells) > 1:\n",
    "                    split_date = cells[0].text.strip()\n",
    "                    split_date = datetime.strptime(split_date, \"%b %d, %Y\").strftime(\"%-m/%-d/%Y\")\n",
    "                    symbol = cells[1].text.strip()\n",
    "                    company_name = cells[2].text.strip()\n",
    "                    split_type = cells[3].text.strip()\n",
    "                    split_ratio = cells[4].text.strip().replace(\" for \", \" : \")\n",
    "                    if \"forward\" not in split_type:\n",
    "                        data.append([split_date, symbol, company_name, split_ratio])\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Extract data from tipranks.com\n",
    "tipranks_data = get_tipranks_data()\n",
    "\n",
    "# Create DataFrame and save to CSV without the Type column\n",
    "df_tipranks = pd.DataFrame(tipranks_data, columns=['Date', 'Symbol', 'Company Name', 'Split Ratio'])\n",
    "output_file_path = '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/Tipranks_Split_Data.csv'\n",
    "df_tipranks.to_csv(output_file_path, index=False)\n",
    "print(f\"Tipranks data has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>-----------------------------HedgeFollow.com Parsing Code-----------------------------<h3>\n",
    "<h4>Code Will Take about a Minute<h4>\n",
    "<h6>url = 'https://www.tipranks.com/calendars/stock-splits/upcoming'<h6>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to /Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/HedgeFollows_Split_Data.csv\n",
      "Filtered data has been saved to /Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/HedgeFollows_Split_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to convert date format from YYYY-MM-DD to MM/DD/YYYY\n",
    "def convert_date_format(date_str):\n",
    "    if pd.isna(date_str) or date_str == \"N/A\":\n",
    "        return \"N/A\"\n",
    "    return datetime.strptime(date_str, '%Y-%m-%d').strftime('%m/%d/%Y')\n",
    "\n",
    "# Setup Chrome options\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Run in headless mode\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "# Setup the Chrome driver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "# URL of the webpage to scrape\n",
    "url = \"https://hedgefollow.com/upcoming-stock-splits.php\"\n",
    "\n",
    "# Open the webpage\n",
    "driver.get(url)\n",
    "\n",
    "# Wait for the table to be present and visible\n",
    "wait = WebDriverWait(driver, 30)\n",
    "table = wait.until(EC.presence_of_element_located((By.ID, \"latest_splits\")))\n",
    "\n",
    "# Initialize lists to store the data\n",
    "stocks = []\n",
    "exchanges = []\n",
    "companies = []\n",
    "split_ratios = []\n",
    "ex_dates = []\n",
    "announcement_dates = []\n",
    "\n",
    "# Iterate over the rows in the table\n",
    "for row in table.find_elements(By.TAG_NAME, \"tr\")[1:]:  # Skip the header row\n",
    "    cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    if len(cols) == 6:  # Adjust the number of columns to match your data\n",
    "        stocks.append(cols[0].text.strip())\n",
    "        exchanges.append(cols[1].text.strip())\n",
    "        companies.append(cols[2].text.strip())\n",
    "        split_ratios.append(cols[3].text.strip())\n",
    "        ex_dates.append(cols[4].text.strip())\n",
    "        announcement_dates.append(cols[5].text.strip())\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "data = {\n",
    "    'Stock': stocks,\n",
    "    'Exchange': exchanges,\n",
    "    'Company Name': companies,\n",
    "    'Split Ratio': split_ratios,\n",
    "    'Ex-Date': ex_dates,\n",
    "    'Announcement Date': announcement_dates\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_file = '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/HedgeFollows_Split_Data.csv'\n",
    "df.to_csv(csv_file, index=False)\n",
    "\n",
    "print(f\"Data has been saved to {csv_file}\")\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Filter the data\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Filter rows for reverse splits (where b > a in the split ratio a:b)\n",
    "reverse_splits = []\n",
    "for index, row in df.iterrows():\n",
    "    split_ratio = row['Split Ratio']\n",
    "    a, b = map(int, split_ratio.split(':'))\n",
    "    if b > a:\n",
    "        reverse_splits.append(row)\n",
    "\n",
    "# Create a new DataFrame with the filtered data\n",
    "reverse_splits_df = pd.DataFrame(reverse_splits)\n",
    "\n",
    "# Change the date format\n",
    "reverse_splits_df['Ex-Date'] = reverse_splits_df['Ex-Date'].apply(convert_date_format)\n",
    "\n",
    "# Rename 'Ex-Date' column to 'Date'\n",
    "reverse_splits_df = reverse_splits_df.rename(columns={'Ex-Date': 'Date'})\n",
    "# Rename 'Ex-Date' column to 'Date'\n",
    "reverse_splits_df = reverse_splits_df.rename(columns={'Stock': 'Symbol'})\n",
    "\n",
    "# Remove the columns 'Announcement Date' and 'Exchange'\n",
    "reverse_splits_df = reverse_splits_df.drop(columns=['Announcement Date', 'Exchange'])\n",
    "\n",
    "# Reorder the columns to move 'Date' to be the first column\n",
    "reverse_splits_df = reverse_splits_df[['Date', 'Symbol', 'Company Name', 'Split Ratio']]\n",
    "\n",
    "# Save the filtered data to a new CSV file\n",
    "output_file_path = '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/HedgeFollows_Split_Data.csv'\n",
    "reverse_splits_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Filtered data has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>-----------------------------Combined Parsed Code-----------------------------<h2>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data has been saved to /Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/Combined_Split_Data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to read and combine data from multiple CSV files\n",
    "def read_and_combine_csv_files(file_paths):\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        df = pd.read_csv(file_path)\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# Function to convert date format from MM/DD/YYYY to datetime object\n",
    "def convert_to_datetime(date_str):\n",
    "    try:\n",
    "        return datetime.strptime(date_str, '%m/%d/%Y')\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Function to choose the most recent date for each unique ticker\n",
    "def get_most_recent_dates(df):\n",
    "    df['Date'] = df['Date'].apply(convert_to_datetime)\n",
    "    most_recent_df = df.loc[df.groupby('Symbol')['Date'].idxmax()]\n",
    "    return most_recent_df\n",
    "\n",
    "# List of input CSV files\n",
    "file_paths = [\n",
    "    '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/HedgeFollows_Split_Data.csv',\n",
    "    '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/StockAnalysis_Split_Data.csv',\n",
    "    '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/Tipranks_Split_Data.csv',\n",
    "    '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/API_Parsed_Data/stock_splits_polygon.csv'\n",
    "]\n",
    "\n",
    "# Combine data from multiple CSV files\n",
    "combined_df = read_and_combine_csv_files(file_paths)\n",
    "\n",
    "# Get the most recent dates for each unique ticker\n",
    "result_df = get_most_recent_dates(combined_df)\n",
    "\n",
    "# Sort by Date in descending order\n",
    "result_df = result_df.sort_values(by='Date', ascending=False)\n",
    "\n",
    "# Convert the Date column back to MM/DD/YYYY format\n",
    "result_df['Date'] = result_df['Date'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "output_file_path = '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/Combined_Split_Data.csv'\n",
    "result_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Combined data has been saved to {output_file_path}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>-----------------------------Send Code To PRIA-----------------------------<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data has been saved to /Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Alpha PRIA/TestData.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r6/0smcfgt9415gwpc747f7ghth0000gn/T/ipykernel_64025/3856053443.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Date'] = filtered_df['Date'].dt.strftime('%m/%d/%Y')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Function to filter data from the past week and future dates\n",
    "def filter_past_week_and_future_data(df, date_column):\n",
    "    # Get today's date\n",
    "    today = datetime.today()\n",
    "    # Calculate the date one week ago\n",
    "    one_week_ago = today - timedelta(days=7)\n",
    "    \n",
    "    # Convert the date column to datetime format\n",
    "    df[date_column] = pd.to_datetime(df[date_column], format='%m/%d/%Y')\n",
    "    \n",
    "    # Filter the DataFrame for rows within the past week and future dates\n",
    "    filtered_data = df[df[date_column] >= one_week_ago]\n",
    "    return filtered_data\n",
    "\n",
    "# Path to the input CSV file (X.csv)\n",
    "input_file_path = '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Parsed_Data/Combined_Split_Data.csv'\n",
    "# Path to the output CSV file (Y.csv)\n",
    "output_file_path = '/Users/ardadinc/Desktop/Market-Insight/Web_Parse_Data/Alpha PRIA/TestData.csv'\n",
    "\n",
    "# Read the input CSV file\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Filter data from the past week and future dates\n",
    "filtered_df = filter_past_week_and_future_data(df, 'Date')\n",
    "\n",
    "# Format the Date column back to MM/DD/YYYY\n",
    "filtered_df['Date'] = filtered_df['Date'].dt.strftime('%m/%d/%Y')\n",
    "\n",
    "# Save the filtered data to the output CSV file\n",
    "filtered_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Filtered data has been saved to {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
